{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from utils.ssim import SSIM, MSSSIM\n",
    "from parameters import Parameters\n",
    "from utils.utils import adjust_learning_rate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset import create_my_data_3ch, BasicDataset\n",
    "from loupe.models import loupe_3ch\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import normalized_root_mse\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "seed_num = 42\n",
    "torch.manual_seed(seed_num)\n",
    "torch.cuda.manual_seed_all(seed_num)\n",
    "np.random.seed(seed_num)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.epochs = 5 #40\n",
    "params.batch_size = 32 # 128\n",
    "params.lr = 0.01 # 0.01\n",
    "params.sparsity = 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project config\n",
    "model_name = params.model_name\n",
    "print(\"model_name:\",model_name)\n",
    "num_epoch = int(params.epochs)\n",
    "batch_size = int(params.batch_size)\n",
    "ssimCriterion = SSIM()\n",
    "msssimCriterion = MSSSIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure directory info\n",
    "run_name = model_name+\"_bs_\"+str(params.batch_size) + \"_ep_\"+str(params.epochs) + \"_lr_\" + str(params.lr)\n",
    "save_dir = join(params.save_weights, run_name)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy, valx, valy, train_mean, train_std = create_my_data_3ch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(trainx))\n",
    "n_val = int(len(valx))\n",
    "dataset_train = BasicDataset(trainx, trainy)\n",
    "dataset_val = BasicDataset(valx, valy)\n",
    "train_loader = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(trainx))\n",
    "n_val = int(len(valx))\n",
    "dataset_train = BasicDataset(trainx, trainy)\n",
    "dataset_val = BasicDataset(valx, valy)\n",
    "train_loader = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_net = loupe_3ch(6,6,params.sparsity)\n",
    "#density_compensation = torch.from_numpy(density_compensation).cuda().requires_grad_(True)\n",
    "criterion = torch.nn.L1Loss().cuda()\n",
    "optimizer = optim.Adam(rec_net.parameters(), lr=float(params.lr), betas=(0.5, 0.999))\n",
    "if cuda:\n",
    "    rec_net = rec_net.cuda()\n",
    "rec_net.train()\n",
    "best_loss = 9999\n",
    "best_model_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    rec_net.train()\n",
    "    optimizer = adjust_learning_rate(epoch, optimizer)\n",
    "    count = 1\n",
    "    t_loss = 0\n",
    "    n_loss = 0\n",
    "    r_loss = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{num_epoch}', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            img_un = batch['img_un'].cuda().float() #[b 6 96 96] n c w h \n",
    "            \n",
    "            img_full_real = batch[\"img_full_real\"].cuda().float()\n",
    "\n",
    "            img_full_real_input = img_full_real#.repeat(1,3,1,1)\n",
    "            \n",
    "            out_pred, out_mask, out_prob = rec_net(img_un)\n",
    "\n",
    "            pred_loss1= criterion(out_pred[:,0,:,:],img_full_real_input[:,0,:,:])\n",
    "            pred_loss2= criterion(out_pred[:,1,:,:],img_full_real_input[:,1,:,:])\n",
    "            pred_loss3= criterion(out_pred[:,2,:,:],img_full_real_input[:,2,:,:])\n",
    "\n",
    "            mask_loss1=  criterion(out_prob[:,0,:,:],out_prob[:,1,:,:])\n",
    "            mask_loss2=  criterion(out_prob[:,1,:,:],out_prob[:,2,:,:])\n",
    "            mask_loss3=  criterion(out_prob[:,2,:,:],out_prob[:,0,:,:])\n",
    "            \n",
    "            n_loss = (pred_loss1+pred_loss2+pred_loss3)/3\n",
    "            r_loss = 0.001 * (mask_loss3+mask_loss1+mask_loss2)\n",
    "            \n",
    "            loss = 0\n",
    "            loss = n_loss - r_loss\n",
    "\n",
    "            #t_loss = t_loss + loss.item()\n",
    "            count += 1\n",
    "            #writer.add_scalar('train/Loss', loss.item(), global_step)\n",
    "            pbar.set_postfix({'loss': n_loss, 'reg':r_loss})\n",
    "  \n",
    "            loss.backward()\n",
    "            #n_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            pbar.update(img_un.shape[0])\n",
    "            global_step += 1\n",
    "    if epoch % 10 == 0:\n",
    "        pred_img = out_pred.detach().cpu().numpy()\n",
    "        #print(\"pred_img.shape\",pred_img.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(pred_img[0,0,:,:], cmap='gray')\n",
    "        #plt.savefig(str(epoch)+\"_img.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_net.eval()\n",
    "psnr_total = 0\n",
    "nmse_total = 0\n",
    "rmse_total = 0\n",
    "ssim_total = 0\n",
    "num = 0\n",
    "with tqdm(total=n_val, desc=f'Epoch {epoch + 1}/{num_epoch}', unit='img') as pbar:\n",
    "    for batch in val_loader:\n",
    "        img_un = batch['img_un'].cuda().float()\n",
    "        img_full_real = batch[\"img_full_real\"].cuda().float()\n",
    "        img_full_real_input = img_full_real#.repeat(1,3,1,1)\n",
    "        out_pred, out_mask, out_prob = rec_net(img_un)\n",
    "\n",
    "        pred_img = out_pred.detach().cpu().numpy()\n",
    "        real_img = img_full_real_input.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(pred_img.shape[0]):\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][0],pred_img[i][0])\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][1],pred_img[i][1])\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][2],pred_img[i][2])\n",
    "\n",
    "            nmse_total += normalized_root_mse(real_img[i][0],pred_img[i][0])\n",
    "            nmse_total += normalized_root_mse(real_img[i][1],pred_img[i][1])\n",
    "            nmse_total += normalized_root_mse(real_img[i][2],pred_img[i][2])\n",
    "\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][0],pred_img[i][0]))\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][1],pred_img[i][1]))\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][2],pred_img[i][2]))\n",
    "\n",
    "            ssim_total += structural_similarity(real_img[i][0],pred_img[i][0],data_range=1)\n",
    "            ssim_total += structural_similarity(real_img[i][1],pred_img[i][1],data_range=1)\n",
    "            ssim_total += structural_similarity(real_img[i][2],pred_img[i][2],data_range=1)\n",
    "            num +=1\n",
    "\n",
    "        pbar.update(img_un.shape[0])\n",
    "\n",
    "psnr_mean = psnr_total / n_val / 3\n",
    "nmse_mean = nmse_total / n_val / 3\n",
    "rmse_mean = rmse_total / n_val / 3\n",
    "ssim_mean = ssim_total / n_val / 3\n",
    "\n",
    "print(\"BASELINE PSNR:%s SSIM:%s NMSE:%s RMSE:%s\" % (psnr_mean,ssim_mean,nmse_mean,rmse_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mask = out_mask.detach().cpu().numpy()\n",
    "prob_mask = prob_mask[0]\n",
    "pred_img = out_pred.detach().cpu().numpy()\n",
    "pred_img = pred_img[0]\n",
    "real_img = img_full_real_input.detach().cpu().numpy()\n",
    "real_img = real_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "plt.suptitle(\"LOUPE, 8x Acceleration\",size='xx-large')\n",
    "for i in range(3):\n",
    "    axes[i].imshow(np.round(prob_mask[i]), cmap='gray', interpolation='none')\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prob_mask[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3,figsize=(12,12))\n",
    "plt.suptitle(\"LOUPE, 4x Acceleration\",size='xx-large')\n",
    "ax[0,0].imshow(pred_img[0],cmap='gray')\n",
    "ax[0,0].set_title('Output')\n",
    "ax[0,1].imshow(real_img[0],cmap='gray')\n",
    "ax[0,1].set_title('Ground Truth')\n",
    "ax[0,2].imshow(np.abs(real_img[0]-pred_img[0]),cmap='gray')\n",
    "ax[0,2].set_title('Difference')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i,0].imshow(pred_img[i],cmap='gray')\n",
    "    ax[i,1].imshow(real_img[i],cmap='gray')\n",
    "    ax[i,2].imshow(np.abs(real_img[i]-pred_img[i]),cmap='jet')\n",
    "    ax[i,0].axis('off')\n",
    "    ax[i,1].axis('off')\n",
    "    ax[i,2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('3 channel, slope=200, sample_slope=200, 40iters, lr=0.01, sparsity=0.25, lambda=0.001, 8x.npy', [prob_mask,pred_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rec_net.state_dict(), '3 channel, slope=200, sample_slope=200, 40iters, lr=0.01, sparsity=0.25, lambda=0.001, 8x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
