{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from utils.ssim import SSIM, MSSSIM\n",
    "from parameters import Parameters\n",
    "from utils.utils import adjust_learning_rate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset import create_my_data_3ch, BasicDataset\n",
    "from loupe.models import rec_unet_3ch\n",
    "from utils.mask import fixed_cartesian_mask_3ch, random_cartesian_mask_3ch, fixed_radial_mask_3ch, rotated_radial_mask_3ch\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import normalized_root_mse\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "seed_num = 42\n",
    "torch.manual_seed(seed_num)\n",
    "torch.cuda.manual_seed_all(seed_num)\n",
    "np.random.seed(seed_num)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.epochs = 5\n",
    "params.batch_size = 32 # 128\n",
    "params.lr = 0.01 # 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project config\n",
    "model_name = params.model_name\n",
    "print(\"model_name:\",model_name)\n",
    "num_epoch = int(params.epochs)\n",
    "batch_size = int(params.batch_size)\n",
    "ssimCriterion = SSIM()\n",
    "msssimCriterion = MSSSIM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure directory info\n",
    "run_name = model_name+\"_bs_\"+str(params.batch_size) + \"_ep_\"+str(params.epochs) + \"_lr_\" + str(params.lr)\n",
    "save_dir = join(params.save_weights, run_name)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy, valx, valy, train_mean, train_std = create_my_data_3ch(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Examples for how to call other type of masks\n",
    "\n",
    "# masks = fixed_cartesian_mask_3ch(0.27) # 4x speed up\n",
    "# masks = fixed_cartesian_mask_3ch(0.13) # 8x speed up\n",
    "\n",
    "# masks = random_cartesian_mask_3ch(0.25) # 4x speed up\n",
    "# masks = random_cartesian_mask_3ch(0.125) # 8x speed up\n",
    "\n",
    "# masks = fixed_radial_mask_3ch(58) # 4x speed up\n",
    "# masks = fixed_radial_mask_3ch(28) # 8x speed up\n",
    "\n",
    "# masks = rotated_radial_mask_3ch(58)\n",
    "masks = rotated_radial_mask_3ch(28)\n",
    "\n",
    "print(np.mean(masks))\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "plt.suptitle(\"Masks\",size='xx-large')\n",
    "plt.tight_layout()\n",
    "for i in range(3):\n",
    "    axes[i].imshow(masks[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(trainx))\n",
    "n_val = int(len(valx))\n",
    "dataset_train = BasicDataset(trainx, trainy)\n",
    "dataset_val = BasicDataset(valx, valy)\n",
    "train_loader = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_net = rec_unet_3ch(6,6)\n",
    "criterion = torch.nn.L1Loss().cuda()\n",
    "optimizer = optim.Adam(rec_net.parameters(), lr=float(params.lr), betas=(0.5, 0.999))\n",
    "if cuda:\n",
    "    rec_net = rec_net.cuda()\n",
    "rec_net.train()\n",
    "best_loss = 9999\n",
    "best_model_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    rec_net.train()\n",
    "    optimizer = adjust_learning_rate(epoch, optimizer)\n",
    "    count = 1\n",
    "    t_loss = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{num_epoch}', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            img_un = batch['img_un'].cuda().float() #[b 6 96 96] n c w h \n",
    "            img_full_real = batch[\"img_full_real\"].cuda().float()\n",
    "\n",
    "            img_full_real_input = img_full_real#.repeat(1,3,1,1)\n",
    "            \n",
    "            masks_pred = rec_net(img_un, torch.tensor(masks).cuda())\n",
    "\n",
    "            pred_loss1= criterion(masks_pred[:,0,:,:],img_full_real_input[:,0,:,:])\n",
    "            pred_loss2= criterion(masks_pred[:,1,:,:],img_full_real_input[:,1,:,:])\n",
    "            pred_loss3= criterion(masks_pred[:,2,:,:],img_full_real_input[:,2,:,:])\n",
    "            \n",
    "            loss = 0\n",
    "            loss =  (pred_loss1+pred_loss2+pred_loss3)/3  #+ params.loss_lambda * criterion(magnitude_double_batch(masks_pred[1]), magnitude_double_batch(img_full)) \n",
    "\n",
    "            t_loss = t_loss + loss.item()\n",
    "            count += 1\n",
    "            pbar.set_postfix({'loss': loss})\n",
    "  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(img_un.shape[0])\n",
    "            global_step += 1\n",
    "    if epoch % 10 == 0:\n",
    "        pred_img = masks_pred.detach().cpu().numpy()\n",
    "        #print(\"pred_img.shape\",pred_img.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(pred_img[0,0,:,:], cmap='gray')\n",
    "        #plt.savefig(str(epoch)+\"_img.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_net.eval()\n",
    "psnr_total = 0\n",
    "nmse_total = 0\n",
    "rmse_total = 0\n",
    "ssim_total = 0\n",
    "num = 0\n",
    "with tqdm(total=n_val, desc=f'Epoch {epoch + 1}/{num_epoch}', unit='img') as pbar:\n",
    "    for batch in val_loader:\n",
    "        img_un = batch['img_un'].cuda().float()\n",
    "        img_full_real = batch[\"img_full_real\"].cuda().float()\n",
    "        img_full_real_input = img_full_real#.repeat(1,3,1,1)\n",
    "        masks_pred = rec_net(img_un, torch.tensor(masks).cuda())\n",
    "\n",
    "        pred_img = masks_pred.detach().cpu().numpy()\n",
    "        real_img = img_full_real_input.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(pred_img.shape[0]):\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][0],pred_img[i][0])\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][1],pred_img[i][1])\n",
    "            psnr_total += peak_signal_noise_ratio(real_img[i][2],pred_img[i][2])\n",
    "\n",
    "            nmse_total += normalized_root_mse(real_img[i][0],pred_img[i][0])\n",
    "            nmse_total += normalized_root_mse(real_img[i][1],pred_img[i][1])\n",
    "            nmse_total += normalized_root_mse(real_img[i][2],pred_img[i][2])\n",
    "\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][0],pred_img[i][0]))\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][1],pred_img[i][1]))\n",
    "            rmse_total += np.sqrt(mean_squared_error(real_img[i][2],pred_img[i][2]))\n",
    "\n",
    "            ssim_total += structural_similarity(real_img[i][0],pred_img[i][0],data_range=1)\n",
    "            ssim_total += structural_similarity(real_img[i][1],pred_img[i][1],data_range=1)\n",
    "            ssim_total += structural_similarity(real_img[i][2],pred_img[i][2],data_range=1)\n",
    "            num +=1\n",
    "\n",
    "        pbar.update(img_un.shape[0])\n",
    "\n",
    "psnr_mean = psnr_total / n_val / 3\n",
    "nmse_mean = nmse_total / n_val / 3\n",
    "rmse_mean = rmse_total / n_val / 3\n",
    "ssim_mean = ssim_total / n_val / 3\n",
    "\n",
    "print(\"BASELINE PSNR:%s SSIM:%s NRMSE:%s RMSE:%s\" % (psnr_mean,ssim_mean,nmse_mean,rmse_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mask = masks\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,5))\n",
    "plt.suptitle(\"LOUPE, 8x Acceleration, separate\",size='xx-large')\n",
    "plt.tight_layout()\n",
    "for i in range(3):\n",
    "    axes[i].imshow(np.round(prob_mask[i]), cmap='gray', interpolation='none')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=0.92, wspace=0.01, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3,figsize=(12,12))\n",
    "plt.suptitle(\"Cartesian, 4x Acceleration\",size='xx-large')\n",
    "plt.tight_layout()\n",
    "ax[0,0].imshow(pred_img[0][0],cmap='gray')\n",
    "ax[0,0].set_title('Output')\n",
    "ax[0,1].imshow(real_img[0][0],cmap='gray')\n",
    "ax[0,1].set_title('Ground Truth')\n",
    "ax[0,2].imshow(np.abs(real_img[0][0]-pred_img[0][0]),cmap='jet')\n",
    "ax[0,2].set_title('Difference')\n",
    "\n",
    "ax[1,0].imshow(pred_img[0][1],cmap='gray')\n",
    "ax[1,1].imshow(real_img[0][1],cmap='gray')\n",
    "ax[1,2].imshow(np.abs(real_img[0][1]-pred_img[0][1]),cmap='jet')\n",
    "\n",
    "ax[2,0].imshow(pred_img[0][2],cmap='gray')\n",
    "ax[2,1].imshow(real_img[0][2],cmap='gray')\n",
    "ax[2,2].imshow(np.abs(real_img[0][2]-pred_img[0][2]),cmap='jet')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i,0].axis('off')\n",
    "    ax[i,1].axis('off')\n",
    "    ax[i,2].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rec_net.state_dict(), 'cartesian, 8x, 3 channel random newnew.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cartesian, 8x, 3 channel random newnew.npy', [prob_mask,pred_img[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
